# Qdrant
QDRANT_URL=
QDRANT_API_KEY=

# Groq
GROQ_API_KEY=

# App
ENV=development

# JWT Settings
JWT_SECRET_KEY=
JWT_ALGORITHM=
JWT_ACCESS_TOKEN_EXPIRE_DAYS=

# Google OAuth
GOOGLE_CLIENT_ID=TO_FILL_YOUR_GOOGLE_CLIENT_ID

# Google Cloud Vision (for OCR)
# Path to your service account JSON file enabling Vision API
GOOGLE_APPLICATION_CREDENTIALS=/absolute/path/to/google-vision-key.json

# Image Embeddings
# Controls which image embedding pipeline runs: auto | remote | local | ocr
# - auto: try remote, then local, then OCR fallback
# - remote: call external embedding API (set URL+KEY below)
# - local: use local CLIP model (downloads once unless CLIP_MODEL_PATH set)
# - ocr: use OCR text-only embeddings (no CLIP inference)
IMAGE_EMBEDDING_MODE=auto

# Remote embedding API (only used when IMAGE_EMBEDDING_MODE=remote or auto)
IMAGE_EMBEDDING_API_URL=
IMAGE_EMBEDDING_API_KEY=

# Local CLIP model path (optional)
# If set, loads CLIP from this folder (no network). Leave empty to use HF cache.
# Example: CLIP_MODEL_PATH=/home/dipak/SIH-25321_MVP/model_cache/clip-vit-base-patch32
CLIP_MODEL_PATH=

# Hugging Face (used for text embedding bge-m3 in OCR path)
HF_API_TOKEN=
# Optional override of the feature-extraction endpoint; default is bge-m3 feature-extraction
HF_API_URL_BGE=